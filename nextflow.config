/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    nf-core/seqqc Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

// Global default params, used in configs
params {
    // TODO nf-core: Specify your pipeline's command line flags
    
    // Input options
    input                      = null // location for the input samplesheet file
    classifier                 = "kraken2"
    fasta                      = "test.fa"
    schema_ignore_params       = "fasta"

    //rasusa subsampling options
    depth_cut_off             = 50 // minimum coverage to subsample the reads to
    // assembly_qc: genomesize is used by confindr for spec
    genomesize                = 5000000 // reference genome size. Valid metric suffixes include Base (b), Kilo (k), Mega (m), Giga (g), Tera (t)

    //confindr options
    confindr_db               = "/mnt/cidgoh-object-storage/database/confindr/confindr_db" //database for confindr. The default database are only for detecting contamination in Escherichia, Listeria, and Salmonella. If you want to run ConFindr on any other genera, you need to build the database following the tutorial at https://olc-bioinformatics.github.io/ConFindr/install/.

    //trimmer options
    trim_tool                 = "fastp"  // Select which trimming tool to use (fastp/trimmomatic/trimgalore) 
    adapter_fasta             = "https://object-arbutus.cloud.computecanada.ca/cidgohshare/database/adaptors/test.fa" // location for adapator database (fasta file)
    save_trimmed_fail         = false //  Check if reads failed in the trimming process need to be saved (True/False, default: False)
    save_merged               = true  // Check if merged reads need to be saved (True/False, default: True)

    // MultiQC options
    multiqc_config             = null
    multiqc_title              = null
    multiqc_logo               = null
    max_multiqc_email_size     = '25.MB'
    multiqc_methods_description = null

    // Taxonomy module options
    skip_kraken                = false
    skip_combinekreports       = false
    skip_kreport2krona         = false
    skip_bracken               = false
    skip_kraken2               = false
    skip_combinebrackenoutputs = false
    skip_dehosting             = false
    skip_subsampling           = false
    skip_confindr              = false

    // kraken2 options
    // Path to Kraken2 database used for querying reads during taxonomic classification
    kraken2_db                 = "/mnt/cidgoh-object-storage/database/minikraken2/minikraken2_v2_8GB_201904_UPDATE"
    // Boolean for whether to output classified reads as a fastq file
    classified_reads           = true
    // Boolean for whether to output unclassified reads as a fastq file
    unclassified_reads         = true

    // centrifuge options
    centrifuge_db              = "/mnt/cidgoh-object-storage/database/centrifuge"

    save_unaligned             = true
    // Boolean for whether to save aligned reads to a fastq file
    save_aligned               = true
    // Boolean for whether to save the output as a SAM file 
    sam_format                 = true

    // Dehosting options
    // Aligner used for dehosting ('minimap2' or 'bwa')
    dehosting_aligner          = 'minimap2'
    // Path to (human) reference genome used for dehosting
    reference_genome           = "/mnt/cidgoh-object-storage/database/reference_genomes/human/GRCh38.p14/GCF_000001405.40/GCF_000001405.40_GRCh38.p14_genomic.fna"
    // ID/name for reference genome 
    ref_genome_id              = 'test'

    // bwa options
    // Whether to sort ('sort') or view ('view') the BAM file obtained from BWA
    bwa_sort_bam               = 'sort'

    // minimap2 options
    // Boolean on whether to output the alignment as a BAM file or a PAF file
    bam_format                 = true
    // Boolean on whether to get Minimap2 to generate CIGAR strings at the cg tag of the PAF file
    cigar_paf_format           = false
    // Boolean on whether to get Minimap2 to move long CIGAR strings to the cg tag in the BAM file
    cigar_bam                  = false

    // samtools options
    // Boolean for whether to get Samtools fastq to generate an interleaved fastq or to write to separate files 
    interleaved                = false

    // Boilerplate options
    outdir                     = null
    tracedir                   = "${params.outdir}/pipeline_info"
    publish_dir_mode           = 'copy'
    email                      = null
    email_on_fail              = null
    plaintext_email            = false
    monochrome_logs            = false
    hook_url                   = null
    help                       = false
    version                    = false
    validate_params            = true
    show_hidden_params         = false
    schema_ignore_params       = 'genomes'

    // Shovill options
    assembler                  = 'spades'

    // CheckM options
    checkm_db                  = false

    // QUAST options
    reference                  = false
    reference_gff              = false
    combine_quast              = false

    // BUSCO options
    busco_lineage              = "auto"
    busco_lineages_path        = "/mnt/cidgoh-object-storage/database/busco"
    busco_config               = false

    // Config options
    custom_config_version      = 'master'
    custom_config_base         = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
    config_profile_description = null
    config_profile_contact     = null
    config_profile_url         = null
    config_profile_name        = null


    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '128.GB'
    max_cpus                   = 16
    max_time                   = '240.h'

}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load nf-core custom profiles from different Institutions
try {
    includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
    System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

// Load nf-core/seqqc custom profiles from different institutions.
// Warning: Uncomment only if a pipeline-specific instititutional config already exists on nf-core/configs!
// try {
//   includeConfig "${params.custom_config_base}/pipeline/seqqc.config"
// } catch (Exception e) {
//   System.err.println("WARNING: Could not load nf-core/config/seqqc profiles: ${params.custom_config_base}/pipeline/seqqc.config")
// }

//plugins {
//  id 'nf-validation@0.2.1'
//}

profiles {
    debug { process.beforeScript = 'echo $HOSTNAME' }
    conda {
        conda.enabled          = false
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    docker {
        docker.enabled         = true
        docker.userEmulation   = true
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    arm {
        docker.runOptions = '-u $(id -u):$(id -g) --platform=linux/amd64'
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    podman {
        podman.enabled         = true
        docker.enabled         = false
        singularity.enabled    = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    shifter {
        shifter.enabled        = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        charliecloud.enabled   = false
    }
    charliecloud {
        charliecloud.enabled   = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
    }
    gitpod {
        executor.name          = 'local'
        executor.cpus          = 16
        executor.memory        = 60.GB
    }
    test      { includeConfig 'conf/test.config'      }
    test_full { includeConfig 'conf/test_full.config' }
    
}

/*
//---------------- Process requirements configuration ------------

process {
  withLabel:process_low {
    cpus = { check_max( 2 * task.attempt, 'cpus' ) }
    memory = { check_max( 8.GB * task.attempt, 'memory' ) }
    time = { check_max( 6.h * task.attempt, 'time' ) }
  }
  withLabel:process_medium {
    cpus = { check_max( 4 * task.attempt, 'cpus' ) }
    memory = { check_max( 30.GB * task.attempt, 'memory' ) }
    time = { check_max( 8.h * task.attempt, 'time' ) }
  }
  withLabel:process_high {
    cpus = { check_max( 12 * task.attempt, 'cpus' ) }
    memory = { check_max( 84.GB * task.attempt, 'memory' ) }
    time = { check_max( 10.h * task.attempt, 'time' ) }
  }
}
*/

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.html"
}

manifest {
    name            = 'nf-core/seqqc'
    author          = """Zohaib Anwar, Jimmy Liu, Jun Duan, Aishwarya Sridhar, David Tong, Mathew Nguyen, Miguel Prieto, Michael Trimble, Soyean Kim and William Hsiao"""
    homePage        = 'https://github.com/nf-core/seqqc'
    description     = """Quality control workflow for short-reads (Illumina) and long-reads (Oxford Nanopore) sequencing data including WGS, Amplicon and Metagenomics"""
    mainScript      = 'main.nf'
    nextflowVersion = '!>=22.01.0'
    version         = '1.0dev'
    doi             = ''
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
